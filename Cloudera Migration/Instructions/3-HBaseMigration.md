# Exercise 3: Migrate an HBase database to HDInsight

## Introduction

In this exercise, you'll migrate an an HBase database from Cloudera to HDInsight. You'll perform the following tasks:

- Examine the existing database currently running on Cloudera.
- Create the virtual infrastructure for an HDInsight HBase cluster, and then create the cluster.
- Use HBase snapshots to transfer data from the Cloudera cluster to the HDInsight cluster.
- Verify that the data has been transferred correctly.

At the end of this process, the Hive database will have been relocated to the HDInsight cluster. Applications that utilize the database for analytical purposes can be reconfigured to connect to the instance on HDInsight.

## Task 1: Examine the existing HBase database

In the existing on-premises system, a Spark application acts as a receiver for messages arriving on a Kafka topic. The Spark application posts writes the data, in batches, to a series of CSV files. A Squoop job periodically uploads the data in these files to HBase. In this exercise, you'll replicate the Cloudera Hive database to an HDInsight cluster.

The first task is to examine the existing database.

![The structure of the existing Kafka/Spark/Squoop/HBase system running on Cloudera](../Images/4-HBaseSystem.png)

---

**NOTE:**
In the example used by by this lab exercise, the files generated by the Spark application have already been created. You will perform HBase import operations manually to simulate Sqoop uploading the data. 

---

1. If you haven't already done so, on your desktop, open a **Command Prompt** window and sign in to the Cloudera virtual machine. The username is **azureuser***. Replace *\<ip_address`>* with the IP address of the virtual machine.

    ```PowerShell
    ssh azureuser@<ip address>
    ```

1. Move to the **apps/hbase** folder:

    ```bash
    cd ~/app/hbase
    ```

1. Start the HBase shell:

    ```bash
    hbase shell
    ```

1. Run the following command:

    ```bash
    create 'flights', 'info', 'departures', 'arrivals', 'delays'
    ```

    This command creates a new table named **flights**, with four column families; **info**, **departures**, **arrivals**, and **delays**.

1. Run the command shown below to verify that the **flights** table has been created successfully:

    ```hbase
    describe 'flights'
    ```

    The output should look like this:

    ```text
    => Hbase::Table - flights
    hbase(main):014:0> describe 'flights'
    Table flights is ENABLED
    flights
    COLUMN FAMILIES DESCRIPTION
    {NAME => 'arrivals', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}
    {NAME => 'delays', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}
    {NAME => 'departures', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}
    {NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}
    4 row(s) in 0.0170 seconds
    ```

1. Quit the hbase shell:

    ```hbase
    exit
    ```

1. At the bash prompt, run the command shown below. This command shows the data in the first batch created by the Spark process. The file contains 9999 records:


    ```bash
    more batch1.csv
    ```
    
    Browse the data, and then press **q** to quit when you are finished.

1. Upload the **batch1.csv** file to HDFS

    ```bash
    hdfs dfs -copyFromLocal batch1.csv
    ```
    
1. Run the following command. This command simulates Sqoop uploading the data in the copy of the **batch1.csv** file in HDFS to the HBase database. It runs a MapReduce task:

    ```bash
    hbase org.apache.hadoop.hbase.mapreduce.ImportTsv \
    -Dimporttsv.separator=',' \
    -Dimporttsv.columns=HBASE_ROW_KEY,\
    info:UniqueCarrier,\
    info:FlightNum,\
    info:TailNum,\
    info:Distance,\
    info:Origin,\
    info:Dest,\
    departures:Year,\
    departures:Month,\
    departures:DayofMonth,\
    departures:DayOfWeek,\
    departures:DepTime,\
    departures:CRSDepTime,\
    arrivals:ArrTime,\
    arrivals:CRSArrTime,\
    arrivals:ActualElapsedTime,\
    arrivals:CRSElapsedTime,\
    arrivals:AirTime,\
    delays:ArrDelay,\
    delays:DepDelay,\
    delays:TaxiIn,\
    delays:TaxiOut,\
    delays:Cancelled,\
    delays:CancellationCode,\
    delays:Diverted,\
    delays:CarrierDelay,\
    delays:WeatherDelay,\
    delays:NASDelay,\
    delays:SecurityDelay,\
    delays:LateAircraftDelay \
    flights \
    batch1.csv
    ```

1. Start the hbase shell again:

    ```bash
    hbase
    ```

1. Run the command shown below:

    ```hbase
    get 'flights', 1
    ```

    This command retrieves the data for the first record from the **flights** table. It should look like this.

    ```text
    COLUMN                                    CELL
    arrivals:ActualElapsedTime               timestamp=1605097033332, value=255
    arrivals:AirTime                         timestamp=1605097033332, value=244
    arrivals:ArrTime                         timestamp=1605097033332, value=1057
    arrivals:CRSArrTime                      timestamp=1605097033332, value=1101
    arrivals:CRSElapsedTime                  timestamp=1605097033332, value=255
    delays:ArrDelay                          timestamp=1605097033332, value=-4
    delays:CancellationCode                  timestamp=1605097033332, value=NA
    delays:Cancelled                         timestamp=1605097033332, value=0
    delays:CarrierDelay                      timestamp=1605097033332, value=NA
    delays:DepDelay                          timestamp=1605097033332, value=-4
    delays:Diverted                          timestamp=1605097033332, value=0
    delays:LateAircraftDelay                 timestamp=1605097033332, value=NA
    delays:NASDelay                          timestamp=1605097033332, value=NA
    delays:SecurityDelay                     timestamp=1605097033332, value=NA
    delays:TaxiIn                            timestamp=1605097033332, value=3
    delays:TaxiOut                           timestamp=1605097033332, value=8
    delays:WeatherDelay                      timestamp=1605097033332, value=NA
    departures:CRSDepTime                    timestamp=1605097033332, value=846
    departures:DayOfWeek                     timestamp=1605097033332, value=6
    departures:DayofMonth                    timestamp=1605097033332, value=1
    departures:DepTime                       timestamp=1605097033332, value=842
    departures:Month                         timestamp=1605097033332, value=1
    departures:Year                          timestamp=1605097033332, value=2000
    info:Dest                                timestamp=1605097033332, value=PHX
    info:Distance                            timestamp=1605097033332, value=1587
    info:FlightNum                           timestamp=1605097033332, value=609
    info:Origin                              timestamp=1605097033332, value=ATL
    info:TailNum                             timestamp=1605097033332, value=N158AW
    info:UniqueCarrier                       timestamp=1605097033332, value=HP
    ```

1. Run this command:

    ```hbase
    count 'flights'
    ```

    This command shows the cumulative number of rows in each data block allocated to the table and its column families, together with a grand total. The grand total should be 9999:

    ```text
    Current count: 1000, row: 1899
    Current count: 2000, row: 2799
    Current count: 3000, row: 3699
    Current count: 4000, row: 4599
    Current count: 5000, row: 5499
    Current count: 6000, row: 6399
    Current count: 7000, row: 7299
    Current count: 8000, row: 8199
    Current count: 9000, row: 9099
    9999 row(s) in 0.9870 seconds

    => 9999
    ```

1. Leave the hbase shell:

    ```hbase
    exit
    ```

## Task 2: Create the HDInsight HBase cluster

In this task, you'll create an HDInsight HBase cluster. You'll reuse the existing network from the previous exercises, but you'll create a new Blob storage account for the cluster. This is because Blob storage provides better performance for HBase than Data Lake storage.

### Create the storage account

1. Return to the Azure portal in the web browser.

1. If the Home page isn't currently displayed, click select the **Home** link in the upper left hand corner:

1. On the Azure Home page, select **Create a resource**.

1. On the **New** page, in the **Search the Marketplace** box, type **storage account network**, and then select **Storage account** from the list that appears.

1. On the **Storage account** page, select **Create**.

1. On the **Basics** tab of the **Create storage account** page, enter the following settings, and then select **Next: Networking**:

    | Field | Value|
    |-|-|
    | Subscription | Select your subscription |
    | Resource group | clusterrg |
    | Storage account name | hbasestorage*nnnn*, where *nnnn* is a random four digit number you select to avoid clashing with other storage accounts |
    | Location | Select the same region used by the Cloudera virtual machine and the **clusterrg** resource group |
    | Performance | Premium |
    | Account Kind | BlockBlobStorage |
    | Replication | Zone-redundant storage (GRS) |

1. On the **Networking** tab, accept the default settings, and then select **Next: Data protection**.

1. On the **Data protection** tab, accept the default settings, and then select **Next: Advanced**.

1. On **Advanced** tab, under **Data Lake Storage Gen2**, select **Enabled** for **Hierarchical namespace**. Leave all other settings at their default values, and then select **Review + create**

1. On the validation page, select **Create**, and wait while the storage account is created.

1. On the Home page in the Azure portal, under **Recent resources**, select **hbasestorage*9999***.

1. On the **hbasestorage*9999*** page select **Access Control (IAM)**:

1. On the **hbasestorage*9999* | Access Control (IAM)** page select **Add**, and then select **Add role assignment**:

1. In the **Add role assignment** pane, enter the following settings, and then select **Save**:

    | Field | Value|
    |-|-|
    | Role | Storage Blob Data Ower |
    | Assign access to | User assigned managed identity |
    | Subscription | Select your subscription |
    | Select | clustermanagedid |

1. Wait while the role is assigned, and then click **Role assignments* to verify that it has been assigned successfully:

### Create the HBase cluster

1. On the Azure Home page, select **Create a resource**.

1. On the **New** page, in the **Search the Marketplace** box, type **Azure HDInsight**, and then select **Azure HDInsight** from the list that appears.

1. On the **Azure HDInsight** page, select **Create**.

1. On the **Basics** tab of the **Create HDInsight cluster** page, enter the following settings, and then select **Next: Storage**:

    | Field | Value|
    |-|-|
    | Subscription | Select your subscription |
    | Resource group | clusterrg |
    | Cluster name | hbasecluster*nnnn*, where *nnnn* is the same random four digit number you selected when you created the storage account (if necessary, you can use a different number, but for consistency try and reuse the same value if possible) |
    | Region | Select the same region used by the Cloudera virtual machine and the **clusterrg** resource group |
    | Cluster type | HBase |
    | Version | HBase 2.1.6 (HDI 4.0) |
    | Enable HBAse accelerated writes | checked |
    | Cluster login name | admin |
    | Cluster login password | Pa55w.rdDemo |
    | Confirm cluster login password | Pa55w.rdDemo |
    | Secure Shell (SSH) username | sshuser |
    | Use cluster login password for SSH | checked |

1. On the **Storage** tab, enter the following settings, and then select **Next: Security + networking**:

    | Field | Value|
    |-|-|
    | Primary storage type | Azure Data Lake Storage Gen2 |
    | Primary storage account | hbasestorage*9999* |
    | Filesystem | cluster*9999* |
    | User-assigned managed identity | clustermanagedid |
    | SQL database for Ambari | leave blank |
    | SQL database for Hive | leave blank |
    | SQL database for Ooozie | leave blank |

1. On the **Security + networking** tab, enter the following settings, and then select **Next: Configuration + pricing**

    | Field | Value|
    |-|-|
    | Enable enterprise security package | Leave unchecked |
    | Minimum TLS version | 1.2 |
    | Virtual network | clustervnet/clusterrg |
    
    Leave all remaining settings on this tab with their default values.

1. On the **Configuration + pricing** tab, reduce the number of **Region nodes** to 3 (to save costs for this exercise), set the **Node size** to **DS12 v2**, and then select **Review + create**.

1. On the validation page, select **Create**, and wait while the cluster is created.

    ---

    **NOTE:** 
    
    This operation may take 15 or 20 minutes to complete

    ---

### Configure the cluster network connectivity

1. On the Home page in the Azure portal, under **Recent resources**, select **llapcluster*9999***.

1. On the **Overview** page for the cluster, under **Dashboards**, select **Ambari home**.

1. Sign in to Ambari as **admin** with password **Pa55w.rdDemo** when prompted. The Ambari page should show that the cluster is running the HDFS, Hive, and Zookeeper services (amongst others).:

    ![The Ambari home page, showing the running services for the Hive cluster.](../Images/3-Ambari-Home.png)

    ---

    **NOTE:**

    The YARN and MapReduce2 services will be shown as only partially available. This is because they are only active on one head node at a time. If that head node fails, they will be started on the remaining head node automatically.

    ---

1. In the left-hand pane of the Ambari page, select **Hosts**. Make a note of the name prefixes and IP addresses of the worker nodes with the prefixes **wn0**, **wn1**, and **wn2**.

    ![The **Hosts** page in Ambari. The names and addresses of the worker nodes are highlighted.](../Images/3-Worker-Addresses.png)

1. Return to the **Command Prompt** window displaying the SSH connection to the Cloudera virtual machine.

1. On the Cloudera virtual machine. run the following command to create a bash shell running as root.

    ```bash
    sudo bash
    ```

1. Edit the **/etc/hosts** file, and add entries for each of the worker nodes in the HDInsight Kafka cluster to the end of the file. The file below shows an example, based on the screenshot shown above:

    ```text
    127.0.0.1 localhost

    # The following lines are desirable for IPv6 capable hosts
    ::1 ip6-localhost ip6-loopback
    fe00::0 ip6-localnet
    ff00::0 ip6-mcastprefix
    ff02::1 ip6-allnodes
    ff02::2 ip6-allrouters
    ff02::3 ip6-allhosts

    # Entries for worker nodes
    10.3.0.11 wn0-llapcl
    10.3.0.4  wn3-llapcl
    10.3.0.14 wn4-llapcl
    ```

1. Run the **ifconfig** command, and make a note of the **inet addr** field for the **eth0** device. In the example shown below, the **inet addr** is 10.10.0.4.

    ```text
    root@onprem:~/apps/kafka# ifconfig
    eth0    Link encap:Ethernet  HWaddr 00:0d:3a:98:f9:70
            inet addr:10.10.0.4  Bcast:10.10.0.255  Mask:255.255.255.0
            inet6 addr: fe80::20d:3aff:fe98:f970/64 Scope:Link
            UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
            RX packets:45434 errors:0 dropped:15 overruns:0 frame:0
            TX packets:51027 errors:0 dropped:0 overruns:0 carrier:0
            collisions:0 txqueuelen:1000
            RX bytes:21979594 (21.9 MB)  TX bytes:11414674 (11.4 MB)

    lo      Link encap:Local Loopback
            inet addr:127.0.0.1  Mask:255.0.0.0
            ...
    ```

1. Run the following command to quit the root shell and return to the azureuser shell.

    ```bash
    exit
    ```

1. In the Azure portal, on the page for **llapcluster*9999***, under **Settings**, select **SSH + Cluster login**. In the **SSH + Cluster login** pane, in the **Hostname** list select your cluster, and then make a note of the **ssh** command you can use to connect to this cluster:

1. On the desktop, open another command prompt window, and run the SSH command you just noted, to sign in to the head node of the Kafka cluster. The password is **Pa55w.rdDemo**:

    ```bash
    ssh sshuser@llapcluster9999-ssh.azurehdinsight.net
    ```

1. Start a shell running as root:

    ```bash
    sudo bash
    ```
1. Edit the file **/etc/hosts**, and add an entry for the Cloudera virtual machine. You noted the IP address of the Cloudera virtual machine earlier. The virtual machine has the name **onprem**, with the FQDN of **onprem.internal.cloudapp.net**. The file below shows an example, using the IP address 10.10.0.4:

    ```text
    127.0.0.1 localhost

    # The following lines are desirable for IPv6 capable hosts
    ::1 ip6-localhost ip6-loopback
    fe00::0 ip6-localnet
    ff00::0 ip6-mcastprefix
    ff02::1 ip6-allnodes
    ff02::2 ip6-allrouters
    ff02::3 ip6-allhosts
    10.3.0.16 hn0-llapcl.kaetua2hhycevkq3hkawfmrwjh.bx.internal.cloudapp.net hn0-llapcl hn0-llapcl.kaetua2hhycevkq3hkawfmrwjh.bx.internal.cloudapp.net.
    ...
    # Cloudera virtual machine
    10.10.0.4 onprem.internal.cloudapp.net onprem
    ```

1. Run the following command to quit the root shell and return to the sshuser shell.

    ```bash
    exit
    ```

1. Connect to the first worker node. The password is **Pa55w.rdDemo**, as before (the example below uses **wn0-llapcl**, although the name of the first node in your cluster may be different):

    ```bash
    ssh wn0-llapcl
    ```

1. Start a shell running as root, edit the **/etc/hosts** file, add the entry for the **onprem** virtual machine as before, and then exit the root shell.

1. Disconnect from the wn0-kafkac node, and return to the head node of the cluster.

1. Repeat the previous three steps for the two remaining worker nodes, **wn1-llapcl** and **wn2-llapcl**.


    ---

    **NOTE:**
    Under some circumstances, the worker nodes might not be named sequentially. For example, you might that they are named **wn3-llapcl** and **wn4-llapcl**, as illustrated in the examples shown above. Check the entries in the **/etc/hosts** file of the head node for the names of these nodes.

    ---



